
* tiny-lsp-client

** Configuration

All of ~tiny-lsp-client~'s features are off by default, to be as onubtrusive as possible. To enable jump-to-definition (as a ~xref~ backend) and completion (as a ~completion-at-point~ function), do e.g. the following:

#+begin_src emacs-lisp
(add-hook 'tlc-mode-hook 'tlc-use-xref)
(add-hook 'tlc-mode-hook 'tlc-use-async-capf)
#+end_src

You can also add ~'tlc-use-*~ only to the major-mode hooks you want, if e.g. you only want xref for some major modes.

* todos:

dir with test projects/repos

for tests, have one .el file per test case. It loads the rust module, runs initialize, starts some LSP server, sends some requests and asserts responses. If fail, either due to crash or enexpected value, maybe then and only then error code is non-0? Can check error code in .sh script. Can have as arg to sh both .el file to run and whether to have gui. gui useful to manually debug, non-gui good for regression testing.

- +phase 1: basics + find definition+
- +phase 2: erlang+
- phase 3: completions (ongoing) 
  - Test with real-world usage to see how smooth it is, and make it smoother
  - Tests for all capf variants
- phase 4: make public
  - architecture
  - error strategy
  - logging
  - test strategy
  - licenses and attribution
- Bugs
  - Higher priority
    - unicode support in URIs, need percentage encoding
    - unicode/utf8/utf16 position offset not working. Add tests for precision,
      i.e., go to definition at the very end and very beginning of symbols.
    - Under observation, knock on wood, seems to be fixed: sometimes core dump
      when doing async completion
    - timestamps not clearing the oldest timestamp
  - Lower priority
    - make max log entry shorter again
    - Sometimes duplicate didOpen/didClose
    - At stop, sometimes get duplicate didOpen due to mode and server out of
      sync
    - If no server in current root, stop should set it as default
    - when doing completions in c++ test file, clangd complained about non
      opened document
    - once, when jump to defintion while starting rust analyzer, seemed to get
      stuck in infinite loop with 0 wait between try recv response. Lot's of RAM
      was being consumed. But it might be fixed once a request timeout is being
      used.
- Improvements
  - Higher priority
    - make erlang_ls etc test dependencies
    - use full sync on didChange as fallback
    - use try_recv_timeout wht 0.1s in rust, so that no busy wait in lisp, but
      still frequent possibilities to C-g. Can also fix exceed lisp nesting
    - if user answers no to restart server, disable mode
  - Lower priority
    - in general, ensure no bad args sent to rust. e.g. stop-server with "path"
      because doesn't start with /
    - make (root, lang) key, so that one project with multiple languages can be
      supported.
    - consider caching didChange like eglot
    - Clean up server.rs by having smaller functions (like read_header) and
      having a flatter sructure since break can return early.
    - tests
      - Use clangd instead of rust-analyzer for rust tests
      - Separate lisp level rust-analyzer tests
      - More unit tests
      - test error during xref or capf
      - Some tests are unstable, especially when running all
    - get inspiration from emacs-module-rs and generalize lisp<->rust conversion
      to encapsulate unsafe code better
    - understands bounds and symbol better for capf
    - understand commit chars, range, etc from LSP better. Check what lsp-mode
      and eglot do
    - completion ideas
      - if interrupted, send dabbrev
      - if interrupted, keep calculating and use that as next last result. So
        like the "cached async" but it keeps on refreashing and doesn't do it
        just once in the beginning.
      - for async, measure how much time it takes to do everything except
        while-no-input. And with. And try to skip it for debug purposes
      - Understand how while-no-input, sit-for, and sleep-for interact.
      - Understand how company completes not just from prefix when used with LSP
      - Understand how lsp-mode and eglot handle async and cached completions

* notes

rust-analzyer completion:
{
  "additionalTextEdits": [],
  "deprecated": false,
  "filterText": "S",
  "kind": 25,
  "label": "S",
  "sortText": "7fffffff",
  "textEdit": {
    "newText": "S",
    "range": {
      "end": {
        "character": 6,
        "line": 493
      },
      "start": {
        "character": 4,
        "line": 493
      }
    }
  }
}
clangd completion:
{
  "detail": "long",
  "filterText": "my_function4",
  "insertText": "my_function4",
  "insertTextFormat": 1,
  "kind": 3,
  "label": " my_function4()",
  "score": 1.0087924003601074,
  "sortText": "407edfe4my_function4",
  "textEdit": {
    "newText": "my_function4",
    "range": {
      "end": {
        "character": 6,
        "line": 25
      },
      "start": {
        "character": 4,
        "line": 25
      }
    }
  }
}
erlang_ls completion:
{
  "kind": 14,
  "label": "when"
},
{
  "kind": 14,
  "label": "xor"
},
{
  "data": {},
  "insertText": "binary_to_atom",
  "insertTextFormat": 1,
  "kind": 3,
  "label": "binary_to_atom/1"
},
{
  "data": {},
  "insertText": "binary_to_existing_atom",
  "insertTextFormat": 1,
  "kind": 3,
  "label": "binary_to_existing_atom/1"
},

It seems like company calls the capf function for every keystroke, and thus
triggering a request towards the LSP. But built-in capf only does it once. So
built-in assumes the retrived once are always valid kind of. Maybe performance
impact. Can consider optimizations.

** async cached interruptible completion

One function for getting completions async in the background. Use run-idle-timer
and while-no-input.

When triggering, check point and symbol at point. If same start and cached
symbol is prefix of current symbol, then use cache if exists. Otherwise need to
calculate new.

* Performance notes

1. Operations inside send/recv threads are essentially free. No GC and no blocking for user. So JSON encode/decode is done there.
2. Operations inside lib.rs are cheap. No GC (except for lisp) and rust is faster than lisp (probably for native compiled lisp too, but would be interesting to compare). However, the user needs to wait.
3. Operations inside tiny-lsp-client.el and other lisp code is expensive.

So prioritize to put operations in 1, and then 2, and only 3 if needed. capf filtering has to be done at 3, and this is where lsp-bridge can avoid big costs. Maybe I can call a rust function to filter? Maybe filtering 50K isn't expensive (that's normal work for counsel "rg --files" and also see this SO QA: https://emacs.stackexchange.com/questions/15276/how-do-i-write-a-simple-completion-at-point-functions-function)
